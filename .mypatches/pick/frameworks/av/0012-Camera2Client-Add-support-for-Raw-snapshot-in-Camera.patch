From 69e13d4bc11292509916bc5bf589c2ed61d5bb50 Mon Sep 17 00:00:00 2001
From: Amit Somani <amitsm@codeaurora.org>
Date: Tue, 2 May 2017 18:39:58 +0530
Subject: [PATCH 12/20] Camera2Client: Add support for Raw snapshot in
 Camera2Client

Added support for Raw snapshot as well as jpeg + raw snapshot.

Change-Id: I83585724714767ef99d58e10483ea28d7769d594
---
 services/camera/libcameraservice/Android.mk   |   1 +
 .../libcameraservice/api1/Camera2Client.cpp   | 106 ++++--
 .../libcameraservice/api1/Camera2Client.h     |  10 +-
 .../api1/QTICamera2Client.cpp                 |  16 +
 .../libcameraservice/api1/QTICamera2Client.h  |   3 +-
 .../api1/qticlient2/CaptureSequencer.h        |   2 +-
 .../api1/qticlient2/Parameters.cpp            |  34 +-
 .../api1/qticlient2/Parameters.h              |   8 +-
 .../api1/qticlient2/QTICaptureSequencer.cpp   | 203 +++++++++--
 .../api1/qticlient2/QTICaptureSequencer.h     |   8 +
 .../api1/qticlient2/QTIParameters.cpp         |  55 +++
 .../api1/qticlient2/QTIParameters.h           |   9 +-
 .../api1/qticlient2/RawProcessor.cpp          | 345 ++++++++++++++++++
 .../api1/qticlient2/RawProcessor.h            |  98 +++++
 14 files changed, 828 insertions(+), 70 deletions(-)
 create mode 100644 services/camera/libcameraservice/api1/qticlient2/RawProcessor.cpp
 create mode 100644 services/camera/libcameraservice/api1/qticlient2/RawProcessor.h

diff --git a/services/camera/libcameraservice/Android.mk b/services/camera/libcameraservice/Android.mk
index 74282ef88..94ad96a34 100644
--- a/services/camera/libcameraservice/Android.mk
+++ b/services/camera/libcameraservice/Android.mk
@@ -59,6 +59,7 @@ LOCAL_SRC_FILES +=  \
     api1/qticlient2/QTIFrameProcessor.cpp \
     api1/qticlient2/StreamingProcessor.cpp \
     api1/qticlient2/JpegProcessor.cpp \
+    api1/qticlient2/RawProcessor.cpp \
     api1/qticlient2/CallbackProcessor.cpp \
     api1/qticlient2/JpegCompressor.cpp \
     api1/qticlient2/CaptureSequencer.cpp \
diff --git a/services/camera/libcameraservice/api1/Camera2Client.cpp b/services/camera/libcameraservice/api1/Camera2Client.cpp
index 61da676c7..301ef8c35 100644
--- a/services/camera/libcameraservice/api1/Camera2Client.cpp
+++ b/services/camera/libcameraservice/api1/Camera2Client.cpp
@@ -38,6 +38,7 @@
 #include "api1/QTICamera2Client.h"
 #include "api1/qticlient2/StreamingProcessor.h"
 #include "api1/qticlient2/JpegProcessor.h"
+#include "api1/qticlient2/RawProcessor.h"
 #include "api1/qticlient2/CaptureSequencer.h"
 #include "api1/qticlient2/CallbackProcessor.h"
 #include "api1/qticlient2/ZslProcessor.h"
@@ -149,6 +150,13 @@ status_t Camera2Client::initializeImpl(TProviderPtr providerPtr)
             mCameraId);
     mJpegProcessor->run(threadName.string());
 
+#ifdef USE_QTI_CAMERA2CLIENT
+    mRawProcessor = new RawProcessor(this, mCaptureSequencer);
+    threadName = String8::format("C2-%d-RawProc",
+            mCameraId);
+    mRawProcessor->run(threadName.string());
+#endif
+
     mZslProcessor = new ZslProcessor(this, mCaptureSequencer);
 
     threadName = String8::format("C2-%d-ZslProc",
@@ -440,6 +448,9 @@ binder::Status Camera2Client::disconnect() {
     mFrameProcessor->requestExit();
     mCaptureSequencer->requestExit();
     mJpegProcessor->requestExit();
+#ifdef USE_QTI_CAMERA2CLIENT
+    mRawProcessor->requestExit();
+#endif
     mZslProcessor->requestExit();
     mCallbackProcessor->requestExit();
 
@@ -453,6 +464,9 @@ binder::Status Camera2Client::disconnect() {
         mFrameProcessor->join();
         mCaptureSequencer->join();
         mJpegProcessor->join();
+#ifdef USE_QTI_CAMERA2CLIENT
+        mRawProcessor->join();
+#endif
         mZslProcessor->join();
         mCallbackProcessor->join();
 
@@ -464,6 +478,9 @@ binder::Status Camera2Client::disconnect() {
     mStreamingProcessor->deletePreviewStream();
     mStreamingProcessor->deleteRecordingStream();
     mJpegProcessor->deleteStream();
+#ifdef USE_QTI_CAMERA2CLIENT
+    mRawProcessor->deleteStream();
+#endif
     mCallbackProcessor->deleteStream();
     mZslProcessor->deleteStream();
 
@@ -783,6 +800,13 @@ status_t Camera2Client::startPreviewL(Parameters &params, bool restart) {
 
     bool previewStreamChanged = mStreamingProcessor->getPreviewStreamId() != lastPreviewStreamId;
 
+#ifdef USE_QTI_CAMERA2CLIENT
+    // deleting raw stream before starting preview
+    if(NO_STREAM != mRawProcessor->getStreamId()) {
+        mRawProcessor->deleteStream();
+    }
+#endif
+
     // We could wait to create the JPEG output stream until first actual use
     // (first takePicture call). However, this would substantially increase the
     // first capture latency on HAL3 devices.
@@ -1448,6 +1472,9 @@ status_t Camera2Client::takePicture(int msgType) {
     int takePictureCounter;
     {
         SharedParameters::Lock l(mParameters);
+#ifdef USE_QTI_CAMERA2CLIENT
+        res = mQTICamera2Client->configureRaw(l.mParameters);
+#endif
         switch (l.mParameters.state) {
             case Parameters::DISCONNECTED:
             case Parameters::STOPPED:
@@ -1504,33 +1531,60 @@ status_t Camera2Client::takePicture(int msgType) {
                 return INVALID_OPERATION;
         }
 
-        ALOGV("%s: Camera %d: Starting picture capture", __FUNCTION__, mCameraId);
-        int lastJpegStreamId = mJpegProcessor->getStreamId();
-        // slowJpegMode will create jpeg stream in CaptureSequencer before capturing
-        if (!l.mParameters.slowJpegMode) {
-            res = updateProcessorStream(mJpegProcessor, l.mParameters);
-        }
+#ifdef USE_QTI_CAMERA2CLIENT
+        const char *str = l.mParameters.params.getPictureFormat();
+        l.mParameters.qtiParams->pictureFormat = l.mParameters.formatStringToEnum(str);
+        if(l.mParameters.qtiParams->pictureFormat == HAL_PIXEL_FORMAT_BLOB) {
+#endif
 
-        // If video snapshot fail to configureStream, try override video snapshot size to
-        // video size
-        if (res == BAD_VALUE && l.mParameters.state == Parameters::VIDEO_SNAPSHOT) {
-            overrideVideoSnapshotSize(l.mParameters);
-            res = updateProcessorStream(mJpegProcessor, l.mParameters);
-        }
-        if (res != OK) {
-            ALOGE("%s: Camera %d: Can't set up still image stream: %s (%d)",
-                    __FUNCTION__, mCameraId, strerror(-res), res);
-            return res;
+            ALOGV("%s: Camera %d: Starting picture capture", __FUNCTION__, mCameraId);
+            int lastJpegStreamId = mJpegProcessor->getStreamId();
+            // slowJpegMode will create jpeg stream in CaptureSequencer before capturing
+            if (!l.mParameters.slowJpegMode) {
+                res = updateProcessorStream(mJpegProcessor, l.mParameters);
+            }
+
+            // If video snapshot fail to configureStream, try override video snapshot size to
+            // video size
+            if (res == BAD_VALUE && l.mParameters.state == Parameters::VIDEO_SNAPSHOT) {
+                overrideVideoSnapshotSize(l.mParameters);
+                res = updateProcessorStream(mJpegProcessor, l.mParameters);
+            }
+            if (res != OK) {
+                ALOGE("%s: Camera %d: Can't set up still image stream: %s (%d)",
+                        __FUNCTION__, mCameraId, strerror(-res), res);
+                return res;
+            }
+
+            // Clear ZSL buffer queue when Jpeg size is changed.
+            bool jpegStreamChanged = mJpegProcessor->getStreamId() != lastJpegStreamId;
+            if (l.mParameters.allowZslMode && jpegStreamChanged) {
+                ALOGV("%s: Camera %d: Clear ZSL buffer queue when Jpeg size is changed",
+                        __FUNCTION__, mCameraId);
+                mZslProcessor->clearZslQueue();
+            }
+
+#ifdef USE_QTI_CAMERA2CLIENT
         }
-        takePictureCounter = ++l.mParameters.takePictureCounter;
 
-        // Clear ZSL buffer queue when Jpeg size is changed.
-        bool jpegStreamChanged = mJpegProcessor->getStreamId() != lastJpegStreamId;
-        if (l.mParameters.allowZslMode && jpegStreamChanged) {
-            ALOGV("%s: Camera %d: Clear ZSL buffer queue when Jpeg size is changed",
-                    __FUNCTION__, mCameraId);
-            mZslProcessor->clearZslQueue();
+        if( l.mParameters.qtiParams->isRawPlusYuv ||
+                l.mParameters.qtiParams->pictureFormat == HAL_PIXEL_FORMAT_RAW10 ) {
+            l.mParameters.getMaxRawSize(&l.mParameters.rawpictureWidth,&l.mParameters.rawpictureHeight);
+            l.mParameters.params.setPictureSize(l.mParameters.rawpictureWidth,l.mParameters.rawpictureHeight);
+            ALOGE("%s: Camera %d: Starting Raw capture", __FUNCTION__, mCameraId);
+            int lastRawStreamId = mRawProcessor->getStreamId();
+            if ( lastRawStreamId ==  Camera2Client::NO_STREAM) {
+                res = updateProcessorStream(mRawProcessor, l.mParameters); // creating raw stream
+                if (res != OK) {
+                    ALOGE("%s: Camera %d: Can't set up still image stream: %s (%d)",
+                            __FUNCTION__, mCameraId, strerror(-res), res);
+                    return res;
+                }
+            }
         }
+#endif
+
+        takePictureCounter = ++l.mParameters.takePictureCounter;
     }
 
     ATRACE_ASYNC_BEGIN(kTakepictureLabel, takePictureCounter);
@@ -1974,6 +2028,12 @@ int Camera2Client::getZslStreamId() const {
     return mZslProcessor->getStreamId();
 }
 
+#ifdef USE_QTI_CAMERA2CLIENT
+int Camera2Client::getRawStreamId() const {
+    return mRawProcessor->getStreamId();
+}
+#endif
+
 status_t Camera2Client::registerFrameListener(int32_t minId, int32_t maxId,
         const wp<camera2::FrameProcessor::FilteredListener>& listener, bool sendPartials) {
     return mFrameProcessor->registerListener(minId, maxId, listener, sendPartials);
diff --git a/services/camera/libcameraservice/api1/Camera2Client.h b/services/camera/libcameraservice/api1/Camera2Client.h
index aa53c1b71..3d1854a4d 100644
--- a/services/camera/libcameraservice/api1/Camera2Client.h
+++ b/services/camera/libcameraservice/api1/Camera2Client.h
@@ -43,6 +43,9 @@ namespace camera2 {
 
 class StreamingProcessor;
 class JpegProcessor;
+#ifdef USE_QTI_CAMERA2CLIENT
+class RawProcessor;
+#endif
 class ZslProcessor;
 class CaptureSequencer;
 class CallbackProcessor;
@@ -139,7 +142,9 @@ public:
     int getCallbackStreamId() const;
     int getRecordingStreamId() const;
     int getZslStreamId() const;
-
+#ifdef USE_QTI_CAMERA2CLIENT
+    int getRawStreamId() const;
+#endif
     status_t registerFrameListener(int32_t minId, int32_t maxId,
             const wp<camera2::FrameProcessor::FilteredListener>& listener,
             bool sendPartials = true);
@@ -224,6 +229,9 @@ private:
 
     sp<camera2::CaptureSequencer> mCaptureSequencer;
     sp<camera2::JpegProcessor> mJpegProcessor;
+#ifdef USE_QTI_CAMERA2CLIENT
+    sp<camera2::RawProcessor> mRawProcessor;
+#endif
     sp<camera2::ZslProcessor> mZslProcessor;
 #ifdef USE_QTI_CAMERA2CLIENT
     sp<QTICamera2Client> mQTICamera2Client;
diff --git a/services/camera/libcameraservice/api1/QTICamera2Client.cpp b/services/camera/libcameraservice/api1/QTICamera2Client.cpp
index f0953a519..2bf139934 100644
--- a/services/camera/libcameraservice/api1/QTICamera2Client.cpp
+++ b/services/camera/libcameraservice/api1/QTICamera2Client.cpp
@@ -45,6 +45,8 @@
 #include "api1/qticlient2/CaptureSequencer.h"
 #include "api1/qticlient2/CallbackProcessor.h"
 #include "api1/qticlient2/ZslProcessor.h"
+#include "api1/qticlient2/RawProcessor.h"
+
 
 
 #define ALOG1(...) ALOGD_IF(gLogLevel >= 1, __VA_ARGS__);
@@ -346,5 +348,19 @@ status_t QTICamera2Client::sendCommand(Parameters &params,int32_t cmd, int32_t a
     return res;
 }
 
+status_t QTICamera2Client::configureRaw(Parameters &params) {
+    char value[PROPERTY_VALUE_MAX];
+    status_t res = OK;
+    sp<Camera2Client> client = mParentClient.promote();
+
+    property_get("persist.camera.raw_yuv", value, "0");
+    params.qtiParams->isRawPlusYuv = atoi(value) > 0 ? true : false;
+
+    if((params.state == Parameters::RECORD) || (params.allowZslMode)) {
+        params.qtiParams->isRawPlusYuv = false;
+    }
+
+    return res;
+}
 } // namespace android
 
diff --git a/services/camera/libcameraservice/api1/QTICamera2Client.h b/services/camera/libcameraservice/api1/QTICamera2Client.h
index 49de2e0cb..334cea921 100644
--- a/services/camera/libcameraservice/api1/QTICamera2Client.h
+++ b/services/camera/libcameraservice/api1/QTICamera2Client.h
@@ -31,6 +31,7 @@
 #define ANDROID_SERVERS_CAMERA_QTICAMERA2CLIENT_H
 
 namespace android {
+
 using namespace camera2;
 
 class Camera2Client;
@@ -47,13 +48,13 @@ public:
     status_t startHFRRecording(Parameters &params);
     void stopHFRRecording(Parameters &params);
     status_t sendCommand(Parameters &params,int32_t cmd, int32_t arg1, int32_t arg2);
+    status_t configureRaw(Parameters &params);
 
 private:
     void stopPreviewForRestart(Parameters &params);
     status_t restartVideoHdr(Parameters &params);
 
 };
-
 }; // namespace android
 
 #endif
diff --git a/services/camera/libcameraservice/api1/qticlient2/CaptureSequencer.h b/services/camera/libcameraservice/api1/qticlient2/CaptureSequencer.h
index 239c4cdaa..2af305628 100644
--- a/services/camera/libcameraservice/api1/qticlient2/CaptureSequencer.h
+++ b/services/camera/libcameraservice/api1/qticlient2/CaptureSequencer.h
@@ -45,6 +45,7 @@ class CaptureSequencer:
             virtual public Thread,
             virtual public FrameProcessor::FilteredListener {
   public:
+    sp<QTICaptureSequencer> mQTICaptureSequencer;
     explicit CaptureSequencer(wp<Camera2Client> client);
     ~CaptureSequencer();
 
@@ -116,7 +117,6 @@ class CaptureSequencer:
 
     wp<Camera2Client> mClient;
     wp<ZslProcessor> mZslProcessor;
-    sp<QTICaptureSequencer> mQTICaptureSequencer;
 
     bool mUseQTICaptureSequencer;
 
diff --git a/services/camera/libcameraservice/api1/qticlient2/Parameters.cpp b/services/camera/libcameraservice/api1/qticlient2/Parameters.cpp
index 4f84adc0a..9e2bc121c 100644
--- a/services/camera/libcameraservice/api1/qticlient2/Parameters.cpp
+++ b/services/camera/libcameraservice/api1/qticlient2/Parameters.cpp
@@ -1939,6 +1939,8 @@ status_t Parameters::set(const String8& paramString) {
     if (validatedParams.videoWidth != videoWidth ||
             validatedParams.videoHeight != videoHeight) {
         if (state == RECORD) {
+            /* supporting jpeg as only picture format in case of video record */
+            newParams.set(CameraParameters::KEY_PICTURE_FORMAT,CameraParameters::PIXEL_FORMAT_JPEG);
             ALOGW("%s: Video size cannot be updated (from %d x %d to %d x %d)"
                     " when recording is active! Ignore the size update!",
                     __FUNCTION__, videoWidth, videoHeight, validatedParams.videoWidth,
@@ -2399,9 +2401,16 @@ const char* Parameters::getStateName(State state) {
 }
 
 int Parameters::formatStringToEnum(const char *format) {
-    return CameraParameters::previewFormatToEnum(format);
+    int ret = -1;
+    ret = CameraParameters::previewFormatToEnum(format);
+    if(-1==ret)
+    {
+        ret = QTIParameters::PictureFormatStringToEnum(format);
+    }
+    return ret;
 }
 
+
 const char* Parameters::formatEnumToString(int format) {
     const char *fmt;
     switch(format) {
@@ -2917,6 +2926,13 @@ Parameters::Size Parameters::getMaxSize(const Vector<Parameters::Size> &sizes) {
     }
     return maxSize;
 }
+void Parameters::getMaxRawSize(int * width , int * height)
+{
+    *width = *height = -1;
+    Parameters::Size s = getMaxSize(getAvailableRawSizes());
+    *width = s.width;
+    *height = s.height;
+}
 
 Vector<Parameters::StreamConfiguration> Parameters::getStreamConfigurations() {
     const int STREAM_CONFIGURATION_SIZE = 4;
@@ -3011,6 +3027,22 @@ Vector<Parameters::Size> Parameters::getAvailableJpegSizes() {
     return jpegSizes;
 }
 
+Vector<Parameters::Size> Parameters::getAvailableRawSizes() {
+    Vector<Parameters::Size> rawSizes;
+    const int JPEG_SIZE_ENTRY_COUNT = 2;
+    const int WIDTH_OFFSET = 0;
+    const int HEIGHT_OFFSET = 1;
+    camera_metadata_ro_entry_t availableRawSizes =
+    staticInfo(ANDROID_SCALER_AVAILABLE_RAW_SIZES);
+    for (size_t i = 0; i < availableRawSizes.count; i+= JPEG_SIZE_ENTRY_COUNT) {
+        int width = availableRawSizes.data.i32[i + WIDTH_OFFSET];
+        int height = availableRawSizes.data.i32[i + HEIGHT_OFFSET];
+        Size sz = {width, height};
+        rawSizes.add(sz);
+    }
+    return rawSizes;
+}
+
 Parameters::CropRegion Parameters::calculateCropRegion(bool previewOnly) const {
 
     float zoomLeft, zoomTop, zoomWidth, zoomHeight;
diff --git a/services/camera/libcameraservice/api1/qticlient2/Parameters.h b/services/camera/libcameraservice/api1/qticlient2/Parameters.h
index 9c7a02167..4a26d884a 100644
--- a/services/camera/libcameraservice/api1/qticlient2/Parameters.h
+++ b/services/camera/libcameraservice/api1/qticlient2/Parameters.h
@@ -56,6 +56,7 @@ struct Parameters {
     int previewTransform; // set by CAMERA_CMD_SET_DISPLAY_ORIENTATION
 
     int pictureWidth, pictureHeight;
+    int rawpictureWidth, rawpictureHeight;
     // Store the picture size before they are overriden by video snapshot
     int pictureWidthLastSet, pictureHeightLastSet;
     bool pictureSizeOverriden;
@@ -273,6 +274,9 @@ struct Parameters {
     // Validate and update camera parameters based on new settings
     status_t set(const String8 &paramString);
 
+    // Helper function to get non-duplicated available output formats
+    SortedVector<int32_t> getAvailableOutputFormats();
+
     // Retrieve the current settings
     String8 get() const;
 
@@ -361,6 +365,7 @@ struct Parameters {
     };
 
     int32_t fpsFromRange(int32_t min, int32_t max) const;
+    void getMaxRawSize(int * width,int * height);
 
 private:
 
@@ -416,10 +421,9 @@ private:
     // return true if the device doesn't support min frame duration metadata tag.
     bool isFpsSupported(const Vector<Size> &size, int format, int32_t fps);
 
-    // Helper function to get non-duplicated available output formats
-    SortedVector<int32_t> getAvailableOutputFormats();
     // Helper function to get available output jpeg sizes
     Vector<Size> getAvailableJpegSizes();
+    Vector<Size> getAvailableRawSizes();
     // Helper function to get maximum size in input Size vector.
     // The maximum size is defined by comparing width first, when width ties comparing height.
     Size getMaxSize(const Vector<Size>& sizes);
diff --git a/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.cpp b/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.cpp
index 3592237dc..e2b321e75 100644
--- a/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.cpp
+++ b/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.cpp
@@ -1,4 +1,5 @@
 /* Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
  */
 /*
  * Copyright (C) 2012 The Android Open Source Project
@@ -42,6 +43,7 @@ QTICaptureSequencer::QTICaptureSequencer(wp<Camera2Client> client):
         mNewAEState(false),
         mNewFrameReceived(false),
         mNewCaptureReceived(false),
+        mNewRawCaptureReceived(false),
         mNewCaptureErrorCnt(0),
         mShutterNotified(false),
         mHalNotifiedShutter(false),
@@ -87,11 +89,11 @@ status_t QTICaptureSequencer::startCapture(int msgType, bool& useQTISequencer) {
     {
         SharedParameters::Lock lp(client->getParameters());
         mBurstCount = lp.mParameters.qtiParams->burstCount;
-
         // Set QTI capture sequencer for ZSL,
         // For AE bracketing,
         if ((mBurstCount > 1) ||
                 (lp.mParameters.allowZslMode) ||
+                (lp.mParameters.qtiParams->isRawPlusYuv) ||
                 (lp.mParameters.qtiParams->autoHDREnabled &&
                 lp.mParameters.qtiParams->isHdrScene)) {
             useQTISequencer = true;
@@ -196,6 +198,23 @@ void QTICaptureSequencer::onCaptureAvailable(nsecs_t timestamp,
     }
 }
 
+void QTICaptureSequencer::onRawCaptureAvailable(nsecs_t timestamp,
+        sp<MemoryBase> captureBuffer, bool captureError) {
+    ATRACE_CALL();
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock l(mInputMutex);
+    mRawCaptureTimestamp = timestamp;
+    mRawCaptureBuffer = captureBuffer;
+    if (!mNewRawCaptureReceived) {
+        mNewRawCaptureReceived = true;
+        if (captureError) {
+            mNewRawCaptureErrorCnt++;
+        } else {
+            mNewRawCaptureErrorCnt = 0;
+        }
+        mNewRawCaptureSignal.signal();
+    }
+}
 
 void QTICaptureSequencer::dump(int fd) {
     String8 result;
@@ -307,6 +326,8 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageIdle(
 QTICaptureSequencer::CaptureState QTICaptureSequencer::manageDone(sp<Camera2Client> &client) {
     status_t res = OK;
     ATRACE_CALL();
+    int pictureFormat;
+    bool isRawPlusYuv;
     mCaptureId++;
     if (mCaptureId >= Camera2Client::kCaptureRequestIdEnd) {
         mCaptureId = Camera2Client::kCaptureRequestIdStart;
@@ -319,6 +340,8 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageDone(sp<Camera2Clie
     int takePictureCounter = 0;
     {
         SharedParameters::Lock l(client->getParameters());
+        pictureFormat = l.mParameters.qtiParams->pictureFormat;
+        isRawPlusYuv = l.mParameters.qtiParams->isRawPlusYuv;
         switch (l.mParameters.state) {
             case Parameters::DISCONNECTED:
                 ALOGW("%s: Camera %d: Discarding image data during shutdown ",
@@ -361,22 +384,44 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageDone(sp<Camera2Clie
     /**
      * Fire the jpegCallback in Camera#takePicture(..., jpegCallback)
      */
-    for (int i = 0; i < mBurstCount; i++) {
-        if (mCaptureBuffer[i] != 0 && res == OK) {
-        ATRACE_ASYNC_END(Camera2Client::kTakepictureLabel, takePictureCounter);
-
-        Camera2Client::SharedCameraCallbacks::Lock
-            l(client->mSharedCameraCallbacks);
-        ALOGV("%s: Sending still image to client", __FUNCTION__);
-        if (l.mRemoteCallback != 0) {
-            l.mRemoteCallback->dataCallback(CAMERA_MSG_COMPRESSED_IMAGE,
-                        mCaptureBuffer[i], NULL);
-        } else {
-            ALOGV("%s: No client!", __FUNCTION__);
+    if (pictureFormat == HAL_PIXEL_FORMAT_BLOB ) {
+        for (int i = 0; i < mBurstCount; i++) {
+            if (mCaptureBuffer[i] != 0 && res == OK) {
+                ATRACE_ASYNC_END(Camera2Client::kTakepictureLabel, takePictureCounter);
+
+                Camera2Client::SharedCameraCallbacks::Lock
+                    l(client->mSharedCameraCallbacks);
+                ALOGV("%s: Sending still image to client", __FUNCTION__);
+                if (l.mRemoteCallback != 0) {
+                    l.mRemoteCallback->dataCallback(CAMERA_MSG_COMPRESSED_IMAGE,
+                            mCaptureBuffer[i], NULL);
+                } else {
+                    ALOGV("%s: No client!", __FUNCTION__);
+                }
+                mCaptureBuffer[i].clear();
+            }
         }
+    }
+
+    if (pictureFormat == HAL_PIXEL_FORMAT_RAW10 || isRawPlusYuv) {
+        for (int i = 0; i < mBurstCount; i++) {
+            if (mRawCaptureBuffer != 0 && res == OK) {
+                ATRACE_ASYNC_END(Camera2Client::kTakepictureLabel, takePictureCounter);
+
+                Camera2Client::SharedCameraCallbacks::Lock
+                    l(client->mSharedCameraCallbacks);
+                ALOGV("%s: Sending Raw image to client", __FUNCTION__);
+                if (l.mRemoteCallback != 0 && isRawPlusYuv) {
+                    l.mRemoteCallback->dataCallback(CAMERA_MSG_COMPRESSED_IMAGE,
+                            mRawCaptureBuffer, NULL);
+                } else {
+                    ALOGV("%s: No client!", __FUNCTION__);
+                }
+                mRawCaptureBuffer.clear();
+            }
         }
-        mCaptureBuffer[i].clear();
     }
+
     return IDLE;
 }
 
@@ -590,16 +635,29 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageStandardCapture(
     outputStreams.push(client->getPreviewStreamId());
 
     int captureStreamId = client->getCaptureStreamId();
-    if (captureStreamId == Camera2Client::NO_STREAM) {
-        res = client->createJpegStreamL(l.mParameters);
-        if (res != OK || client->getCaptureStreamId() == Camera2Client::NO_STREAM) {
-            ALOGE("%s: Camera %d: cannot create jpeg stream for slowJpeg mode: %s (%d)",
-                  __FUNCTION__, client->getCameraId(), strerror(-res), res);
-            return DONE;
+
+    if (l.mParameters.qtiParams->pictureFormat == HAL_PIXEL_FORMAT_BLOB) {
+        if (captureStreamId == Camera2Client::NO_STREAM) {
+            res = client->createJpegStreamL(l.mParameters);
+            if (res != OK || client->getCaptureStreamId() == Camera2Client::NO_STREAM) {
+                ALOGE("%s: Camera %d: cannot create jpeg stream for slowJpeg mode: %s (%d)",
+                      __FUNCTION__, client->getCameraId(), strerror(-res), res);
+                return DONE;
+            }
         }
+        outputStreams.push(client->getCaptureStreamId());
+
     }
 
-    outputStreams.push(client->getCaptureStreamId());
+    if(l.mParameters.qtiParams->pictureFormat == HAL_PIXEL_FORMAT_RAW10 ||
+            l.mParameters.qtiParams->isRawPlusYuv) {
+        int rawStreamId = client->getRawStreamId();
+        if (rawStreamId != Camera2Client::NO_STREAM) {
+            outputStreams.push(client->getRawStreamId());
+        } else {
+            return DONE;
+        }
+    }
 
     if (l.mParameters.previewCallbackFlags &
             CAMERA_FRAME_CALLBACK_FLAG_ENABLE_MASK) {
@@ -672,7 +730,8 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageStandardCaptureWait
     status_t res;
     ATRACE_CALL();
     Mutex::Autolock l(mInputMutex);
-
+    int pictureFormat;
+    bool isRawPlusYuv;
 
     // Wait for shutter callback
     while (!mHalNotifiedShutter) {
@@ -697,6 +756,11 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageStandardCaptureWait
         ALOGW("Timed out waiting for shutter notification");
         return DONE;
     }
+    {
+        SharedParameters::Lock l(client->getParameters());
+        pictureFormat = l.mParameters.qtiParams->pictureFormat;
+        isRawPlusYuv = l.mParameters.qtiParams->isRawPlusYuv;
+    }
 
     // Wait for new metadata result (mNewFrame)
     while (!mNewFrameReceived) {
@@ -708,13 +772,28 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageStandardCaptureWait
     }
 
     // Wait until jpeg was captured by JpegProcessor
-    while (mNewFrameReceived && !mNewCaptureReceived) {
-        res = mNewCaptureSignal.waitRelative(mInputMutex, kWaitDuration);
-        if (res == TIMED_OUT) {
-            mTimeoutCount--;
-            break;
+    if (pictureFormat == HAL_PIXEL_FORMAT_BLOB) {
+        while (mNewFrameReceived && !mNewCaptureReceived) {
+            res = mNewCaptureSignal.waitRelative(mInputMutex, kWaitDuration);
+            if (res == TIMED_OUT) {
+                mTimeoutCount--;
+                break;
+            }
         }
     }
+
+    // Wait until raw was captured by RawProcessor
+    if (pictureFormat == HAL_PIXEL_FORMAT_RAW10 || isRawPlusYuv) {
+        while (mNewFrameReceived && !mNewRawCaptureReceived) {
+            res = mNewRawCaptureSignal.waitRelative(mInputMutex, kWaitDuration);
+            if (res == TIMED_OUT) {
+                mTimeoutCount--;
+                break;
+            }
+        }
+    }
+
+    if (pictureFormat == HAL_PIXEL_FORMAT_BLOB) {
     if (mNewCaptureReceived) {
         if (mNewCaptureErrorCnt > kMaxRetryCount) {
             ALOGW("Exceeding multiple retry limit of %d due to buffer drop", kMaxRetryCount);
@@ -726,37 +805,81 @@ QTICaptureSequencer::CaptureState QTICaptureSequencer::manageStandardCaptureWait
         }
     }
 
+    }
+
+    if (pictureFormat == HAL_PIXEL_FORMAT_RAW10 || isRawPlusYuv) {
+        if (mNewRawCaptureReceived) {
+            if (mNewRawCaptureErrorCnt > kMaxRetryCount) {
+                ALOGE("Exceeding multiple retry limit of %d due to buffer drop", kMaxRetryCount);
+                return DONE;
+            } else if (mNewRawCaptureErrorCnt > 0) {
+                ALOGE("Capture error happened, retry %d...", mNewRawCaptureErrorCnt);
+                mNewRawCaptureReceived = false;
+                return STANDARD_CAPTURE;
+            }
+        }
+    }
+
     if (mTimeoutCount <= 0) {
         ALOGW("Timed out waiting for capture to complete");
         return DONE;
     }
-    if (mNewFrameReceived && mNewCaptureReceived) {
+
+    if (mNewFrameReceived ) {
         for (int i = 0; i < mBurstCount; i++) {
-            if (mNewFrameId[i] != (mCaptureId + i)) {
-                ALOGW("Mismatched capture frame IDs: Expected %d, got %d",
-                        mCaptureId, mNewFrameId[0]);
+            if (mNewCaptureReceived || mNewRawCaptureReceived) {
+                if (mNewFrameId[i] != (mCaptureId + i)) {
+                    ALOGW("Mismatched capture frame IDs: Expected %d, got %d",
+                            mCaptureId, mNewFrameId[0]);
+                }
             }
             camera_metadata_entry_t entry;
             entry = mNewFrame[i].find(ANDROID_SENSOR_TIMESTAMP);
             if (entry.count == 0) {
                 ALOGE("No timestamp field in capture frame!");
             } else if (entry.count == 1) {
-                if (entry.data.i64[i] != mCaptureTimestamp[i]) {
+                if (mNewCaptureReceived && entry.data.i64[i] != mCaptureTimestamp[i]) {
+                    ALOGW("Mismatched capture timestamps: Metadata frame %" PRId64 ","
+                                " captured buffer %" PRId64,
+                                entry.data.i64[i],
+                                mCaptureTimestamp[i]);
+                }
+                if (mNewRawCaptureReceived && entry.data.i64[i] != mCaptureTimestamp[i]) {
                     ALOGW("Mismatched capture timestamps: Metadata frame %" PRId64 ","
-                            " captured buffer %" PRId64,
-                            entry.data.i64[i],
-                            mCaptureTimestamp[i]);
+                                " captured buffer %" PRId64,
+                                entry.data.i64[i],
+                                mCaptureTimestamp[i]);
                 }
             } else {
                 ALOGE("Timestamp metadata is malformed!");
             }
         }
-        client->removeFrameListener(mCaptureId, mCaptureId + 1 + mBurstCount, this);
-
-        mNewFrameReceived = false;
-        mNewCaptureReceived = false;
-        return DONE;
+        client->removeFrameListener(mCaptureId, mCaptureId + 1, this);
+
+        if(pictureFormat == HAL_PIXEL_FORMAT_BLOB ) {
+            if(mNewCaptureReceived) {
+                if (isRawPlusYuv) {
+                    if(mNewRawCaptureReceived) {
+                        mNewFrameReceived = false;
+                        mNewCaptureReceived = false;
+                        mNewRawCaptureReceived = false;
+                        return DONE;
+                    }
+                }
+                else {
+                    mNewFrameReceived = false;
+                    mNewCaptureReceived = false;
+                    return DONE;
+                }
+            }
+        } else if((pictureFormat == HAL_PIXEL_FORMAT_RAW10 || isRawPlusYuv) &&
+                    mNewRawCaptureReceived ) {
+                mNewFrameReceived = false;
+                mNewRawCaptureReceived = false;
+                return DONE;
+        }
     }
+
     return STANDARD_CAPTURE_WAIT;
 }
 
diff --git a/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.h b/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.h
index e8fb5eea7..3ad0bd312 100644
--- a/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.h
+++ b/services/camera/libcameraservice/api1/qticlient2/QTICaptureSequencer.h
@@ -1,4 +1,5 @@
 /* Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
  */
 /*
  * Copyright (C) 2012 The Android Open Source Project
@@ -75,6 +76,8 @@ class QTICaptureSequencer:
     // Notifications from the JPEG processor
     void onCaptureAvailable(nsecs_t timestamp, sp<MemoryBase> captureBuffer, bool captureError);
 
+    void onRawCaptureAvailable(nsecs_t timestamp, sp<MemoryBase> captureBuffer, bool captureError);
+
     void dump(int fd);
 
     bool threadLoop();
@@ -100,10 +103,15 @@ class QTICaptureSequencer:
     Condition mNewFrameSignal;
 
     bool mNewCaptureReceived;
+    bool mNewRawCaptureReceived;
     int32_t mNewCaptureErrorCnt;
+    int32_t mNewRawCaptureErrorCnt;
     nsecs_t mCaptureTimestamp[MAX_BURST_COUNT_PER_SHUTTER];
+    nsecs_t mRawCaptureTimestamp;
     sp<MemoryBase> mCaptureBuffer[MAX_BURST_COUNT_PER_SHUTTER];
+    sp<MemoryBase> mRawCaptureBuffer;
     Condition mNewCaptureSignal;
+    Condition mNewRawCaptureSignal;
 
     bool mShutterNotified; // Has CaptureSequencer sent shutter to Client
     bool mHalNotifiedShutter; // Has HAL sent shutter to CaptureSequencer
diff --git a/services/camera/libcameraservice/api1/qticlient2/QTIParameters.cpp b/services/camera/libcameraservice/api1/qticlient2/QTIParameters.cpp
index 468e8ce1c..144f95884 100644
--- a/services/camera/libcameraservice/api1/qticlient2/QTIParameters.cpp
+++ b/services/camera/libcameraservice/api1/qticlient2/QTIParameters.cpp
@@ -197,6 +197,9 @@ const char HISTOGRAM_DISABLE[] = "disable";
 const char KEY_QTI_SUPPORTED_DIS_MODES[] = "dis-values";
 const char KEY_QTI_DIS[] = "dis";
 
+// Values for raw image formats
+const char QTIParameters::QC_PIXEL_FORMAT_BAYER_MIPI_RAW_10RGGB[] = "bayer-mipi-10rggb";
+
 status_t QTIParameters::initialize(void *parametersParent,
             sp<CameraDeviceBase> device, sp<CameraProviderManager> manager) {
     status_t res = OK;
@@ -215,6 +218,7 @@ status_t QTIParameters::initialize(void *parametersParent,
     uint32_t tag = 0;
     isoValue = -1;
     exposureTime = -1;
+    isRawPlusYuv = false;
 
     // Temp Initialize
     ParentParams->params.set("max-contrast", 10);
@@ -299,6 +303,35 @@ status_t QTIParameters::initialize(void *parametersParent,
                 ISO_AUTO);
     }
 
+    String8 supportedPicutreFormats;
+    SortedVector<int32_t> outputFormats = ParentParams->getAvailableOutputFormats();
+    bool addComma = false;
+    for (size_t i=0; i < outputFormats.size(); i++) {
+        if (addComma)
+            supportedPicutreFormats += ",";
+        addComma = true;
+        switch (outputFormats[i]) {
+            case HAL_PIXEL_FORMAT_RAW10:
+                supportedPicutreFormats += PictureFormatEnumToString(outputFormats[i]);
+                break;
+            case HAL_PIXEL_FORMAT_BLOB:
+                supportedPicutreFormats += CameraParameters::PIXEL_FORMAT_JPEG;
+                break;
+
+            default:
+                ALOGW("%s: Camera %d: Unknown preview format: %x",
+                        __FUNCTION__, ParentParams->cameraId, outputFormats[i]);
+                addComma = false;
+                break;
+        }
+    }
+
+    ParentParams->params.set(CameraParameters::KEY_SUPPORTED_PICTURE_FORMATS,
+        supportedPicutreFormats);
+    ParentParams->params.set(CameraParameters::KEY_PICTURE_FORMAT,
+        CameraParameters::PIXEL_FORMAT_JPEG);
+    pictureFormat = PictureFormatStringToEnum(ParentParams->params.getPictureFormat());
+
     //Sharpness
     res = CameraMetadata::getTagFromName(KEY_QTI_VENDOR_SHARPNESS_RANGE, vTags.get(), &tag);
     camera_metadata_ro_entry_t availableSharpnessRange = ParentParams->staticInfo(tag);
@@ -1183,6 +1216,28 @@ int32_t  QTIParameters::setContinuousISO(const char *isoVal, CameraParameters2&
     return BAD_VALUE;
 }
 
+const char*  QTIParameters::PictureFormatEnumToString(int format)
+{
+    switch (format) {
+        case HAL_PIXEL_FORMAT_RAW10:
+            return QC_PIXEL_FORMAT_BAYER_MIPI_RAW_10RGGB;
+        default:
+            ALOGE("%s: Unknown picuture format enum %d",
+                    __FUNCTION__, format);
+            return "unknown";
+        }
+}
+
+int QTIParameters::PictureFormatStringToEnum(const char * format)
+{
+        return
+        !strcmp(format, CameraParameters::PIXEL_FORMAT_JPEG) ?
+                HAL_PIXEL_FORMAT_BLOB :    // jpeg
+        !strcmp(format, QC_PIXEL_FORMAT_BAYER_MIPI_RAW_10RGGB) ?
+            HAL_PIXEL_FORMAT_RAW10 :    // RGB10
+        -1;
+}
+
 }; // namespace camera2
 }; // namespace android
 
diff --git a/services/camera/libcameraservice/api1/qticlient2/QTIParameters.h b/services/camera/libcameraservice/api1/qticlient2/QTIParameters.h
index 109805996..cba3bba53 100644
--- a/services/camera/libcameraservice/api1/qticlient2/QTIParameters.h
+++ b/services/camera/libcameraservice/api1/qticlient2/QTIParameters.h
@@ -91,7 +91,6 @@ private:
     int64_t exposureTime;
     cam_manual_wb_parm_t manualWb;
     int32_t aeBracketValues[MAX_BURST_COUNT_AE_BRACKETING];
-
     enum flashMode_t {
         FLASH_MODE_RED_EYE = ANDROID_CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE,
         FLASH_MODE_INVALID = -1
@@ -114,6 +113,8 @@ public:
     bool Hdr1xEnable;
     bool HdrSceneEnable;
     metadata_vendor_id_t vendorTagId;
+    bool isRawPlusYuv;
+    int pictureFormat;
     // Sets up default QTI parameters
     status_t initialize(void *parametersParent, sp<CameraDeviceBase> device, sp<CameraProviderManager> manager);
     // Validate and update camera parameters based on new settings
@@ -125,6 +126,10 @@ public:
     static int wbModeStringToEnum(const char *wbMode);
     static int sceneModeStringToEnum(const char *sceneMode);
 
+    static const char* PictureFormatEnumToString(int format);
+
+    static int PictureFormatStringToEnum(const char * format);
+
 private:
     int32_t setContinuousISO(const char *isoValue, CameraParameters2& newParams);
     int32_t setExposureTime(const char *expTimeStr, CameraParameters2& newParams);
@@ -132,6 +137,8 @@ private:
     int32_t parseGains(const char *gainStr, double &r_gain,
             double &g_gain, double &b_gain);
     const char *flashModeEnumToString(flashMode_t flashMode);
+
+    static const char QC_PIXEL_FORMAT_BAYER_MIPI_RAW_10RGGB[];
 };
 
 }; // namespace camera2
diff --git a/services/camera/libcameraservice/api1/qticlient2/RawProcessor.cpp b/services/camera/libcameraservice/api1/qticlient2/RawProcessor.cpp
new file mode 100644
index 000000000..9e2b2d55d
--- /dev/null
+++ b/services/camera/libcameraservice/api1/qticlient2/RawProcessor.cpp
@@ -0,0 +1,345 @@
+/* Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
+ */
+/*
+ * Copyright (C) 2012 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "Camera2-RawProcessor"
+#define ATRACE_TAG ATRACE_TAG_CAMERA
+//#define LOG_NDEBUG 0
+
+#include <netinet/in.h>
+#include <inttypes.h>
+
+#include <binder/MemoryBase.h>
+#include <binder/MemoryHeapBase.h>
+#include <utils/Log.h>
+#include <utils/Trace.h>
+#include <gui/Surface.h>
+
+#include "common/CameraDeviceBase.h"
+#include "api1/Camera2Client.h"
+#include "api1/qticlient2/Camera2Heap.h"
+#include "api1/qticlient2/CaptureSequencer.h"
+#include "api1/qticlient2/RawProcessor.h"
+#include "api1/qticlient2/QTICaptureSequencer.h"
+
+
+#define QCAMERA_DUMP_FRM_LOCATION "/data/misc/camera/"
+
+namespace android {
+namespace camera2 {
+
+RawProcessor::RawProcessor(
+    sp<Camera2Client> client,
+    wp<CaptureSequencer> sequencer):
+        Thread(false),
+        mDevice(client->getCameraDevice()),
+        mSequencer(sequencer),
+        mClient(client),
+        mId(client->getCameraId()),
+        mCaptureDone(false),
+        mCaptureSuccess(false),
+        mCaptureStreamId(NO_STREAM) {
+}
+
+RawProcessor::~RawProcessor() {
+    ALOGV("%s: Exit", __FUNCTION__);
+    deleteStream();
+}
+
+void RawProcessor::onFrameAvailable(const BufferItem& /*item*/) {
+    Mutex::Autolock l(mInputMutex);
+    ALOGV("%s", __FUNCTION__);
+    if (!mCaptureDone) {
+        mCaptureDone = true;
+        mCaptureSuccess = true;
+        mCaptureDoneSignal.signal();
+    }
+}
+
+void RawProcessor::onBufferAcquired(const BufferInfo& /*bufferInfo*/) {
+    // Intentionally left empty
+}
+
+void RawProcessor::onBufferReleased(const BufferInfo& bufferInfo) {
+    ALOGV("%s", __FUNCTION__);
+    if (bufferInfo.mError) {
+        // Only lock in case of error, since we get one of these for each
+        // onFrameAvailable as well, and scheduling may delay this call late
+        // enough to run into later preview restart operations, for non-error
+        // cases.
+        // b/29524651
+        ALOGV("%s: Raw buffer lost", __FUNCTION__);
+        Mutex::Autolock l(mInputMutex);
+        mCaptureDone = true;
+        mCaptureSuccess = false;
+        mCaptureDoneSignal.signal();
+    }
+}
+
+status_t RawProcessor::updateStream(const Parameters &params) {
+    ATRACE_CALL();
+    ALOGV("%s", __FUNCTION__);
+    status_t res;
+
+    Mutex::Autolock l(mInputMutex);
+
+    sp<CameraDeviceBase> device = mDevice.promote();
+    if (device == 0) {
+        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
+        return INVALID_OPERATION;
+    }
+
+    // Find out buffer size for Raw
+    ssize_t maxRawSize = ((params.rawpictureWidth*params.rawpictureHeight*2) + 4095U) & ~4095U;
+    if (maxRawSize <= 0) {
+        ALOGE("%s: Camera %d: raw buffer size (%zu) is invalid ",
+                __FUNCTION__, mId, maxRawSize);
+        return INVALID_OPERATION;
+    }
+
+    if (mCaptureConsumer == 0) {
+        // Create CPU buffer queue endpoint
+        sp<IGraphicBufferProducer> producer;
+        sp<IGraphicBufferConsumer> consumer;
+        BufferQueue::createBufferQueue(&producer, &consumer);
+        mCaptureConsumer = new CpuConsumer(consumer, 1);
+        mCaptureConsumer->setFrameAvailableListener(this);
+        mCaptureConsumer->setName(String8("Camera2-RawConsumer"));
+        mCaptureWindow = new Surface(producer);
+    }
+
+    // Since ashmem heaps are rounded up to page size, don't reallocate if
+    // the capture heap isn't exactly the same size as the required Raw buffer
+    const size_t HEAP_SLACK_FACTOR = 2;
+    if (mCaptureHeap == 0 ||
+            (mCaptureHeap->getSize() < static_cast<size_t>(maxRawSize)) ||
+            (mCaptureHeap->getSize() >
+                    static_cast<size_t>(maxRawSize) * HEAP_SLACK_FACTOR) ) {
+        // Create memory for API consumption
+        mCaptureHeap.clear();
+        mCaptureHeap =
+                new MemoryHeapBase(maxRawSize, 0, "Camera2Client::CaptureHeap");
+        if (mCaptureHeap->getSize() == 0) {
+            ALOGE("%s: Camera %d: Unable to allocate memory for capture",
+                    __FUNCTION__, mId);
+            return NO_MEMORY;
+        }
+    }
+    ALOGE("%s: Camera %d: Raw capture heap now %zu bytes; requested %zd bytes",
+            __FUNCTION__, mId, mCaptureHeap->getSize(), maxRawSize);
+
+    if (mCaptureStreamId != NO_STREAM) {
+        // Check if stream parameters have to change
+        CameraDeviceBase::StreamInfo streamInfo;
+        res = device->getStreamInfo(mCaptureStreamId, &streamInfo);
+        if (res != OK) {
+            ALOGE("%s: Camera %d: Error querying capture output stream info: "
+                    "%s (%d)", __FUNCTION__,
+                    mId, strerror(-res), res);
+            return res;
+        }
+
+        if (streamInfo.width != (uint32_t)params.rawpictureWidth ||
+                streamInfo.height != (uint32_t)params.rawpictureHeight) {
+            ALOGV("%s: Camera %d: Deleting stream %d since the buffer dimensions changed",
+                __FUNCTION__, mId, mCaptureStreamId);
+            res = device->deleteStream(mCaptureStreamId);
+            if (res == -EBUSY) {
+                ALOGV("%s: Camera %d: Device is busy, call updateStream again "
+                      " after it becomes idle", __FUNCTION__, mId);
+                return res;
+            } else if (res != OK) {
+                ALOGE("%s: Camera %d: Unable to delete old output stream "
+                        "for capture: %s (%d)", __FUNCTION__,
+                        mId, strerror(-res), res);
+                return res;
+            }
+            mCaptureStreamId = NO_STREAM;
+        }
+    }
+
+    if (mCaptureStreamId == NO_STREAM) {
+        // Create stream for HAL production
+        res = device->createStream(mCaptureWindow,
+                params.rawpictureWidth, params.rawpictureHeight,
+                HAL_PIXEL_FORMAT_RAW10, HAL_DATASPACE_ARBITRARY,
+                CAMERA3_STREAM_ROTATION_0, &mCaptureStreamId);
+        if (res != OK) {
+            ALOGE("%s: Camera %d: Can't create output stream for capture: "
+                    "%s (%d)", __FUNCTION__, mId,
+                    strerror(-res), res);
+            return res;
+        }
+        res = device->addBufferListenerForStream(mCaptureStreamId, this);
+        if (res != OK) {
+              ALOGE("%s: Camera %d: Can't add buffer listeneri: %s (%d)",
+                    __FUNCTION__, mId, strerror(-res), res);
+              return res;
+        }
+    }
+    return OK;
+}
+
+status_t RawProcessor::deleteStream() {
+    ATRACE_CALL();
+
+    Mutex::Autolock l(mInputMutex);
+
+    if (mCaptureStreamId != NO_STREAM) {
+        sp<CameraDeviceBase> device = mDevice.promote();
+        if (device == 0) {
+            ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
+            return INVALID_OPERATION;
+        }
+
+        device->deleteStream(mCaptureStreamId);
+
+        mCaptureHeap.clear();
+        mCaptureWindow.clear();
+        mCaptureConsumer.clear();
+
+        mCaptureStreamId = NO_STREAM;
+    }
+    return OK;
+}
+
+int RawProcessor::getStreamId() const {
+    Mutex::Autolock l(mInputMutex);
+    return mCaptureStreamId;
+}
+
+bool RawProcessor::threadLoop() {
+    status_t res;
+
+    bool captureSuccess = false;
+    {
+        Mutex::Autolock l(mInputMutex);
+        while (!mCaptureDone) {
+            res = mCaptureDoneSignal.waitRelative(mInputMutex,
+                    kWaitDuration);
+            if (res == TIMED_OUT) return true;
+        }
+
+        captureSuccess = mCaptureSuccess;
+        mCaptureDone = false;
+    }
+
+    res = processNewCapture(captureSuccess);
+
+    return true;
+}
+
+status_t RawProcessor::processNewCapture(bool captureSuccess) {
+    ATRACE_CALL();
+    status_t res;
+    sp<Camera2Heap> captureHeap;
+    sp<MemoryBase> captureBuffer;
+
+    CpuConsumer::LockedBuffer imgBuffer;
+
+    if (captureSuccess) {
+        Mutex::Autolock l(mInputMutex);
+        if (mCaptureStreamId == NO_STREAM) {
+            ALOGW("%s: Camera %d: No stream is available", __FUNCTION__, mId);
+            return INVALID_OPERATION;
+        }
+
+        res = mCaptureConsumer->lockNextBuffer(&imgBuffer);
+        if (res != OK) {
+            if (res != BAD_VALUE) {
+                ALOGE("%s: Camera %d: Error receiving still image buffer: "
+                        "%s (%d)", __FUNCTION__,
+                        mId, strerror(-res), res);
+            }
+            return res;
+        }
+
+        ALOGV("%s: Camera %d: Still capture available", __FUNCTION__,
+                mId);
+
+        if (imgBuffer.format != HAL_PIXEL_FORMAT_RAW10) {
+            ALOGE("%s: Camera %d: Unexpected format for still image: "
+                    "%x, expected %x", __FUNCTION__, mId,
+                    imgBuffer.format,
+                    HAL_PIXEL_FORMAT_RAW10);
+            mCaptureConsumer->unlockBuffer(imgBuffer);
+            return OK;
+        }
+
+        // Find size of Raw image
+        size_t RawSize = 0;
+        if (imgBuffer.format == HAL_PIXEL_FORMAT_RAW10) {
+                RawSize = (imgBuffer.width*imgBuffer.height/4)*5;
+        }
+
+        size_t heapSize = mCaptureHeap->getSize();
+        if (RawSize > heapSize) {
+            ALOGW("%s: Raw image is larger than expected, truncating "
+                    "(got %zu, expected at most %zu bytes)",
+                    __FUNCTION__, RawSize, heapSize);
+            RawSize = heapSize;
+        }
+
+        // TODO: Optimize this to avoid memcopy
+        captureBuffer = new MemoryBase(mCaptureHeap, 0, RawSize);
+        void* captureMemory = mCaptureHeap->getBase();
+        memcpy(captureMemory, imgBuffer.data, RawSize);
+        {
+            sp<Camera2Client> client = mClient.promote();
+            if (client == 0) {
+                ALOGE("%s: Camera %d: Client does not exist", __FUNCTION__, mId);
+                return INVALID_OPERATION;
+            }
+            SharedParameters::Lock l(client->getParameters());
+            if(l.mParameters.qtiParams->isRawPlusYuv) {
+                dumpRawSnapshot(imgBuffer,captureMemory,RawSize);
+            }
+        }
+
+        mCaptureConsumer->unlockBuffer(imgBuffer);
+    }
+
+    sp<CaptureSequencer> sequencer = mSequencer.promote();
+    if (sequencer != 0) {
+        sequencer->mQTICaptureSequencer->onRawCaptureAvailable(imgBuffer.timestamp, captureBuffer, !captureSuccess);
+    }
+    return OK;
+}
+
+void RawProcessor::dumpRawSnapshot(CpuConsumer::LockedBuffer & imgBuffer,void * captureBuffer,size_t RawSize)
+{
+    String8 buf;
+    int width=0,height=0;
+
+    width = imgBuffer.width;
+    height = imgBuffer.height;
+    buf.appendFormat(QCAMERA_DUMP_FRM_LOCATION"%" PRId64 "r_%dx%d_%" PRId64 ".raw",
+            imgBuffer.timestamp,width, height,imgBuffer.frameNumber);
+
+    int file_fd = open(buf.string(), O_RDWR| O_CREAT, 0777);
+    if (file_fd >= 0) {
+        ssize_t written_len = write(file_fd, captureBuffer, RawSize);
+        ALOGD("written number of bytes %zd", written_len);
+        close(file_fd);
+    } else {
+        ALOGE("failed to open file to dump image");
+    }
+}
+
+}; // namespace camera2
+}; // namespace android
diff --git a/services/camera/libcameraservice/api1/qticlient2/RawProcessor.h b/services/camera/libcameraservice/api1/qticlient2/RawProcessor.h
new file mode 100644
index 000000000..b7def3b23
--- /dev/null
+++ b/services/camera/libcameraservice/api1/qticlient2/RawProcessor.h
@@ -0,0 +1,98 @@
+/* Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
+ */
+/*
+ * Copyright (C) 2012 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef ANDROID_SERVERS_CAMERA_CAMERA2_RAWPROCESSOR_H
+#define ANDROID_SERVERS_CAMERA_CAMERA2_RAWPROCESSOR_H
+
+#include <utils/Thread.h>
+#include <utils/String16.h>
+#include <utils/Vector.h>
+#include <utils/Mutex.h>
+#include <utils/Condition.h>
+#include <gui/CpuConsumer.h>
+
+#include "camera/CameraMetadata.h"
+
+namespace android {
+
+class Camera2Client;
+class CameraDeviceBase;
+class MemoryHeapBase;
+
+namespace camera2 {
+
+class CaptureSequencer;
+struct Parameters;
+
+/***
+ * Still image capture output image processing
+ */
+class RawProcessor:
+            public Thread, public CpuConsumer::FrameAvailableListener,
+            public camera3::Camera3StreamBufferListener {
+  public:
+    RawProcessor(sp<Camera2Client> client, wp<CaptureSequencer> sequencer);
+    ~RawProcessor();
+
+    // CpuConsumer listener implementation
+    void onFrameAvailable(const BufferItem& item);
+
+    // Camera3StreamBufferListener implementation
+    void onBufferAcquired(const BufferInfo& bufferInfo) override;
+    void onBufferReleased(const BufferInfo& bufferInfo) override;
+
+    status_t updateStream(const Parameters &params);
+    status_t deleteStream();
+    int getStreamId() const;
+
+    void dump(int fd, const Vector<String16>& args) const;
+  private:
+    static const nsecs_t kWaitDuration = 10000000; // 10 ms
+    wp<CameraDeviceBase> mDevice;
+    wp<CaptureSequencer> mSequencer;
+    wp<Camera2Client> mClient;
+    int mId;
+
+    mutable Mutex mInputMutex;
+    bool mCaptureDone;
+    bool mCaptureSuccess;
+    Condition mCaptureDoneSignal;
+
+    enum {
+        NO_STREAM = -1
+    };
+
+    int mCaptureStreamId;
+    sp<CpuConsumer>    mCaptureConsumer;
+    sp<Surface>        mCaptureWindow;
+    sp<MemoryHeapBase> mCaptureHeap;
+
+    virtual bool threadLoop();
+
+    status_t processNewCapture(bool captureSuccess);
+
+    void dumpRawSnapshot(CpuConsumer::LockedBuffer & imgBuffer,void * captureBuffer,size_t RawSize);
+
+};
+
+
+}; //namespace camera2
+}; //namespace android
+
+#endif
-- 
2.17.1

